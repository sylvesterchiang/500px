{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding adversarial examples using stochastic optimization\n",
    "\n",
    "While the initial method of adversarial example generation presented by Goodfellow capitalized on the gradient signs, it is also possible to generate adversarial examples by optimizing a noise pattern to disrupt the softmax classification. In this paradigm you train a deep learning network to learn what noise patterns lead to misclassifications, and can be used for targeted attacks. \n",
    "\n",
    "The concepts used in this notebook were from: https://github.com/Hvass-Labs/TensorFlow-Tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import inception\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I have a pretrained CNN model, so I built the architecture in Keras. Keras compiles down to Tensorflow\n",
    "# so it's possible to use TF as a backend, like I will do below\n",
    "\n",
    "from keras.backend import manual_variable_initialization \n",
    "manual_variable_initialization(True)\n",
    "\n",
    "# A sequential model with dropout layers\n",
    "model = Sequential() \n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#Installing MNIST data\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original accuracy of the MNIST dataset: 0.960099995136261\n"
     ]
    }
   ],
   "source": [
    "# Just checking to see that the model that I loaded up actually works. 96% is pretty bad but my computer is slow\n",
    "# so I just ran a CNN for one epoch to get this accuracy. Definitely something to be fixed in future iterations.\n",
    "\n",
    "from keras.metrics import categorical_accuracy as accuracy\n",
    "labels = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    model.load_weights('cnn_weights3.h5')\n",
    "    \n",
    "    xs = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "    ys = model(xs)\n",
    "\n",
    "    acc_value = accuracy(labels, ys)\n",
    "\n",
    "    res = (acc_value.eval(feed_dict={xs: x_test,\n",
    "                                    labels: y_test,\n",
    "                                    K.learning_phase(): 0}))\n",
    "    print(\"The original accuracy of the MNIST dataset: {}\".format(np.mean(res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 500px challenge\n",
    "\n",
    "So this challenge is to generate adversarial examples that fool a classifier to misclassify a 2 into a 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function is used to initialize only uninitilized variables. This is useful because otherwise\n",
    "#TF would write over my loaded CNN model causing it to classify with completely random accuracy. \n",
    "def initialize_uninitialized(sess):\n",
    "    global_vars          = tf.global_variables()\n",
    "    is_not_initialized   = sess.run([tf.is_variable_initialized(var) for var in global_vars])\n",
    "    not_initialized_vars = [v for (v, f) in zip(global_vars, is_not_initialized) if not f]\n",
    "\n",
    "    #print[str(i.name) for i in not_initialized_vars] # only for testing\n",
    "    if len(not_initialized_vars):\n",
    "        sess.run(tf.variables_initializer(not_initialized_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some basic paramters of the training model\n",
    "img_size = 28\n",
    "num_channels = 1\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "num_batches = int(x_train.shape[0] / batch_size)\n",
    "\n",
    "#Creating a variable collection called adversary_variables\n",
    "#Only these will be optimized in the training process\n",
    "ADVERSARY_VARIABLES = 'adversary_variables'\n",
    "collections = [tf.GraphKeys.GLOBAL_VARIABLES, ADVERSARY_VARIABLES]\n",
    "\n",
    "#A place holder for the image data\n",
    "x_image = tf.placeholder(tf.float32, (None, img_size, img_size, num_channels))\n",
    "\n",
    "#What the network will modify to misclassify examples\n",
    "x_noise = tf.Variable(tf.zeros([img_size, img_size, num_channels]),\n",
    "                  name='x_noise', collections=collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_adv(noise_limit, target_cls=6, noise_l2_weight=0.2):\n",
    "    \n",
    "    #Clipping the noise so that it doesn't perturb the image too much\n",
    "    x_noise_clip = tf.assign(x_noise, tf.clip_by_value(x_noise,\n",
    "                                                   -noise_limit,\n",
    "                                                   noise_limit))\n",
    "    \n",
    "    #adding the noise to the imaeg data\n",
    "    x_noisy_image = x_image + x_noise    \n",
    "    #Clipping it again so that none of the values fall outisde the range of the original MNIST data\n",
    "    x_noisy_image = tf.clip_by_value(x_noisy_image, 0.0, 1.0)\n",
    "    \n",
    "    #Getting a list of variables to be tuned\n",
    "    adversary_variables = tf.get_collection('adversary_variables')\n",
    "    #print([var.name for var in adversary_variables])\n",
    "    \n",
    "    \"\"\"\n",
    "    Creating model output and input\n",
    "    \"\"\"\n",
    "    #ys is the output of the model (a logits output)\n",
    "    ys = model(x_noisy_image)\n",
    "    #labels are the \"true\" output. In this example, we will be putting in misclassification\n",
    "    #as the \"true\" output to make the network learn how output that prediction.\n",
    "    labels = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "    \n",
    "    \"\"\"\n",
    "    Our loss function has two parts:\n",
    "    loss is the regular corss entropy loss of the prediction with the ground truth.\n",
    "    l2_loss_noise is a regularization tool to ensure that the noise values are so large\n",
    "    that the noisy image no longer resembles the initial image. \n",
    "    \"\"\"\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=ys, labels=labels))\n",
    "    l2_loss_noise = noise_l2_weight * tf.nn.l2_loss(x_noise)\n",
    "    \n",
    "    loss_adversary = loss + l2_loss_noise\n",
    "    #optimize only for the adversary variables. \n",
    "    optimizer_adversary = tf.train.AdamOptimizer(learning_rate=0.1).\\\n",
    "        minimize(loss_adversary, var_list=adversary_variables)\n",
    "        \n",
    "    #generate a matrix of target classes to use as labels for optimization\n",
    "    target_labels = np.zeros(10)\n",
    "    target_labels[target_cls] = 1\n",
    "    target_labels = np.repeat([target_labels], batch_size, axis=0)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        #Load CNN weights, initialize TF variables\n",
    "        model.load_weights('cnn_weights3.h5')\n",
    "        sess.run(tf.variables_initializer([x_noise]))\n",
    "        initialize_uninitialized(sess)\n",
    "    \n",
    "        for e in range(5):\n",
    "            \n",
    "            for i in range(num_batches):\n",
    "                \n",
    "                _, loss = sess.run([optimizer_adversary, loss_adversary], feed_dict={\n",
    "                    x_image:x_train[i*batch_size: (i+1)*batch_size],\n",
    "                    labels:target_labels,\n",
    "                    K.learning_phase():0\n",
    "                })\n",
    "                \n",
    "                sess.run(x_noise_clip)\n",
    "                \n",
    "            print('finished optimizing epoch {}'.format(e))\n",
    "            pred = sess.run(ys, feed_dict={\n",
    "                x_image:x_test,\n",
    "                K.learning_phase():0\n",
    "            })\n",
    "            print('percentage of correctly classified images:')\n",
    "            print(np.sum(np.argmax(pred, axis=1) == np.argmax(y_test, axis=1) / (x_test.shape[0] + 0.0))\n",
    "            print('percentage of images classified as target class:')\n",
    "            print(np.sum(np.argmax(pred, axis=1) == target_cls) / (x_test.shape[0] + 0.0))\n",
    "            print('===================')\n",
    "            \n",
    "        return x_noise.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished optimizing epoch 0\n",
      "percentage of correctly classified images:\n",
      "0.0\n",
      "percentage of images classified as target class:\n",
      "0.0924\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sylvester/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:69: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished optimizing epoch 1\n",
      "percentage of correctly classified images:\n",
      "0.0\n",
      "percentage of images classified as target class:\n",
      "0.0924\n",
      "===================\n",
      "finished optimizing epoch 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-177-5c3bf5061b10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_adv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_l2_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.015\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-176-1e2d8e31adca>\u001b[0m in \u001b[0;36mgen_adv\u001b[0;34m(noise_limit, target_cls, noise_l2_weight)\u001b[0m\n\u001b[1;32m     64\u001b[0m             pred = sess.run(ys, feed_dict={\n\u001b[1;32m     65\u001b[0m                 \u001b[0mx_image\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             })\n\u001b[1;32m     68\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'percentage of correctly classified images:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sylvester/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sylvester/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sylvester/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/sylvester/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sylvester/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "noise = gen_adv(noise_limit=0.35, target_cls=6, noise_l2_weight=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11684664"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the adversarial noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adding the noise to the test images\n",
    "noisy_test = []\n",
    "\n",
    "for i in x_test[:100]:\n",
    "    noisy_test.append(i + noise.reshape((28, 28, 1)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95328003"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x13c914da0>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADHCAYAAAAJSqg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nioMhpPTtBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13df91860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(x_test[0].squeeze())\n",
    "plt.title('original image')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(x_test[0].squeeze() + noise.squeeze() * 100)\n",
    "plt.title('image with added noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the chart for the challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = np.where(np.argmax(y_test, axis=1) == 6)\n",
    "class_six = x_test[ind]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
